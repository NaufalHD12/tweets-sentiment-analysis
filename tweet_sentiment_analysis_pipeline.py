# -*- coding: utf-8 -*-
"""Copy of Tweet - Sentiment Analysis Pipeline

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13hYcepBt0jBof9qgyeV94FekWo1W1RpN
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install tfx==1.15.0

import tensorflow as tf
from tfx.components import CsvExampleGen, StatisticsGen, SchemaGen, ExampleValidator, Transform, Trainer, Tuner
from tfx.proto import example_gen_pb2
from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext
import os

"""# Data Pipeline"""

PIPELINE_NAME = "tweet-pipeline"
SCHEMA_PIPELINE_NAME = "tweet-tfdv-schema"

#Directory untuk menyimpan artifact yang akan dihasilkan
PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)

# Path to a SQLite DB file to use as an MLMD storage.
METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')

# Output directory where created models from the pipeline will be exported.
SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)

DATA_ROOT = '/content/drive/MyDrive/tweet'

interactive_context = InteractiveContext(pipeline_root=PIPELINE_ROOT)

"""## Creating Data Ingestion Stages

In this project, I'll do data ingestion using CsvExampleGen() component that provided by TFX.
"""

output = example_gen_pb2.Output(
    split_config = example_gen_pb2.SplitConfig(splits=[
        example_gen_pb2.SplitConfig.Split(name="train", hash_buckets=8),
        example_gen_pb2.SplitConfig.Split(name="eval", hash_buckets=2)
    ])
)
example_gen = CsvExampleGen(input_base=DATA_ROOT, output_config=output)

"""The code above is configuring an output for a data ingestion component in a machine learning pipeline, specifically using TensorFlow Extended (TFX). It defines a SplitConfig for managing how the input data is divided into different datasets or splits. The configuration specifies two splits: "train" and "eval." The "train" split is allocated 8 hash buckets, while the "eval" split receives 2 hash buckets. This setup determines the proportion of data that goes into each split, often used for training and evaluation purposes. The CsvExampleGen component is then initialized with a specified input directory (DATA_ROOT) and the defined output configuration, enabling the ingestion of CSV data files into the pipeline with the specified data splitting strategy.

To see the component **ExampleGen** interactively, I'll run it using the **InteractiveContext()** that I previously defined.
"""

interactive_context.run(example_gen)

"""## Creating Data Validation Stages

### StatisticsGen()
For the next step, I will create a summary statistic using the **StatisticsGen()** component. The component has an input parameter in the form of examples to receive the dataset from the ExampleGen component.
"""

statistics_gen = StatisticsGen(
    examples=example_gen.outputs["examples"]
)


interactive_context.run(statistics_gen)

interactive_context.show(statistics_gen.outputs["statistics"])

"""### SchemaGen
Next, I need to create a data schema. I use the **SchemaGen** component to do this. This component will receive the summary statistic input.
"""

schema_gen = SchemaGen(statistics=statistics_gen.outputs["statistics"]
)
interactive_context.run(schema_gen)

interactive_context.show(schema_gen.outputs["schema"])

"""Based on the data schema display above, it is known that the dataset we use consists of three features, namely "id", "tweet" and "label". The first feature has a integer type, second feature has an integer type, and the third has a byte type. In addition, based on the data schema above, both features must be complete for each dataset.

### ExampleValidator()
The next step is to identify anomalies in the dataset. This process is done using the **ExampleValidator()** component provided by TFX. This component requires the output of statistics_gen and schema_gen as input parameters.
"""

example_validator = ExampleValidator(
    statistics=statistics_gen.outputs['statistics'],
    schema=schema_gen.outputs['schema']
)
interactive_context.run(example_validator)

interactive_context.show(example_validator.outputs['anomalies'])

"""Based on the validation results above, there are no anomalies in the dataset we used in this project.

## Creating Data Preprocessing Stages

After performing data validation, the next step is to perform data preprocessing. The goal of this step is to transform raw data into data that is ready to be used to train the model. In this project, I use TFT and the Transform component to perform data preprocessing.

When performing data preprocessing, it is highly recommended that you place the preprocessing function into a separate module. This is done because the Transform component will receive input in the form of a module file containing the preprocessing function.
"""

TRANSFORM_MODULE_FILE = "tweet_transform.py"

# Commented out IPython magic to ensure Python compatibility.
# %%writefile {TRANSFORM_MODULE_FILE}
# 
# import tensorflow as tf
# LABEL_KEY = "label"
# FEATURE_KEY = "tweet"
# def transformed_name(key):
#     """Renaming transformed features"""
#     return key + "_xf"
# def preprocessing_fn(inputs):
#     """
#     Preprocess input features into transformed features
# 
#     Args:
#         inputs: map from feature keys to raw features.
# 
#     Return:
#         outputs: map from feature keys to transformed features.
#     """
# 
#     outputs = {}
# 
#     outputs[transformed_name(FEATURE_KEY)] = tf.strings.lower(inputs[FEATURE_KEY])
# 
#     outputs[transformed_name(LABEL_KEY)] = tf.cast(inputs[LABEL_KEY], tf.int64)
# 
#     return outputs

"""This code defines a TensorFlow Transform module that preprocesses input data for a machine learning pipeline. It imports TensorFlow and sets two constants, LABEL_KEY and FEATURE_KEY, representing the keys for the "label" and "tweet" features, respectively. The transformed_name function appends "_xf" to a given key, indicating a transformed feature. The preprocessing_fn function takes a dictionary of raw input features and returns a dictionary of transformed features. Specifically, it converts the tweet text to lowercase using tf.strings.lower and casts the label to an integer of type int64 using tf.cast. This transformation prepares the data for subsequent model training by ensuring consistent text formatting and data types."""

transform  = Transform(
    examples=example_gen.outputs['examples'],
    schema= schema_gen.outputs['schema'],
    module_file=os.path.abspath(TRANSFORM_MODULE_FILE)
)
interactive_context.run(transform)

"""# Model Development

- transformed_name(key): This function appends "_xf" to a given key, effectively renaming features to indicate that they have been transformed. This is useful for distinguishing between raw and processed features within the pipeline.
- gzip_reader_fn(filenames): This function reads compressed TFRecord files using TensorFlow's TFRecordDataset with GZIP compression. It returns a dataset object that can be used to iterate over the records in the files. This is important for efficiently loading large datasets that have been compressed to save space.
- input_fn(file_pattern, tf_transform_output, num_epochs, batch_size=64): This function creates a TensorFlow dataset for training or evaluation by reading files that match a given pattern. It uses the transformed feature specification from tf_transform_output to parse the data and batch it. The dataset is configured to iterate for a specified number of epochs and batch size, and it identifies the label using the transformed label key.
- model_builder(): This function constructs a Keras model for binary classification. It defines the model architecture, including input preprocessing with text vectorization, embedding, pooling, dropout, and dense layers. The model is compiled with binary cross-entropy loss and an Adam optimizer, and a summary of the model is printed. The function returns the compiled model ready for training.
- _get_serve_tf_examples_fn(model, tf_transform_output): This function defines a serving function that processes serialized tf.Example inputs for model inference. It uses the transformation graph to apply the same preprocessing as during training. The function returns a callable that can be used to generate predictions on transformed features, making it suitable for deployment.
- run_fn(fn_args: FnArgs): This is the main function that orchestrates the training and saving of the model. It sets up logging and callbacks for TensorBoard, early stopping, and model checkpointing. It loads the transformation output, prepares the training and validation datasets, adapts the text vectorization layer, builds and trains the model, and finally saves the trained model with a serving signature for deployment. This function is designed to be executed as part of a TFX pipeline.

In this section, I'll create and train the model using the **Trainer** component. This component will need some inputs like a file module that contains a training function.
"""

TRAINER_MODULE_FILE = "tweet_trainer.py"

# Commented out IPython magic to ensure Python compatibility.
# %%writefile {TRAINER_MODULE_FILE}
# import tensorflow as tf
# from tensorflow import keras
# import tensorflow_transform as tft
# import os
# from tfx.components.trainer.fn_args_utils import FnArgs
# 
# LABEL_KEY = "label"
# FEATURE_KEY = "tweet"
# 
# def transformed_name(key):
#     """Renaming transformed features"""
#     return key + "_xf"
# 
# def gzip_reader_fn(filenames):
#     """Loads compressed data"""
#     return tf.data.TFRecordDataset(filenames, compression_type='GZIP')
# 
# 
# def input_fn(file_pattern,
#              tf_transform_output,
#              num_epochs,
#              batch_size=64)->tf.data.Dataset:
#     """Get post_tranform feature & create batches of data"""
# 
#     # Get post_transform feature spec
#     transform_feature_spec = (
#         tf_transform_output.transformed_feature_spec().copy())
# 
#     # create batches of data
#     dataset = tf.data.experimental.make_batched_features_dataset(
#         file_pattern=file_pattern,
#         batch_size=batch_size,
#         features=transform_feature_spec,
#         reader=gzip_reader_fn,
#         num_epochs=num_epochs,
#         label_key = transformed_name(LABEL_KEY))
#     return dataset
# 
# 
# # Vocabulary size and number of words in a sequence.
# VOCAB_SIZE = 10000
# SEQUENCE_LENGTH = 100
# 
# vectorize_layer = keras.layers.TextVectorization(
#     standardize="lower_and_strip_punctuation",
#     max_tokens=VOCAB_SIZE,
#     output_mode='int',
#     output_sequence_length=SEQUENCE_LENGTH)
# 
# 
# embedding_dim=16
# def model_builder():
#     """Build machine learning model"""
#     inputs = tf.keras.Input(shape=(1,), name=transformed_name(FEATURE_KEY), dtype=tf.string)
#     reshaped_narrative = tf.keras.layers.Lambda(lambda x: tf.reshape(x, [-1]))(inputs)
#     x = vectorize_layer(reshaped_narrative)
#     x = keras.layers.Embedding(VOCAB_SIZE, embedding_dim, name="embedding")(x)
#     x = keras.layers.GlobalAveragePooling1D()(x)
#     x = keras.layers.Dropout(0.8)(x)
#     x = keras.layers.Dense(64, activation='relu')(x)
#     x = keras.layers.Dropout(0.8)(x)
#     x = keras.layers.Dense(32, activation="relu")(x)
#     outputs = keras.layers.Dense(1, activation='sigmoid')(x)
# 
#     model = keras.Model(inputs=inputs, outputs=outputs)
# 
#     model.compile(
#         loss='binary_crossentropy',
#         optimizer=tf.keras.optimizers.Adam(0.01),
#         metrics=[tf.keras.metrics.BinaryAccuracy()]
#     )
# 
#     model.summary()
#     return model
# 
# 
# 
# def _get_serve_tf_examples_fn(model, tf_transform_output):
# 
#     model.tft_layer = tf_transform_output.transform_features_layer()
# 
#     @tf.function
#     def serve_tf_examples_fn(serialized_tf_examples):
# 
#         feature_spec = tf_transform_output.raw_feature_spec()
# 
#         feature_spec.pop(LABEL_KEY)
# 
#         parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)
# 
#         transformed_features = model.tft_layer(parsed_features)
# 
#         # get predictions using the transformed features
#         return model(transformed_features)
# 
#     return serve_tf_examples_fn
# 
# def run_fn(fn_args: FnArgs) -> None:
# 
#     log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), 'logs')
# 
#     tensorboard_callback = tf.keras.callbacks.TensorBoard(
#         log_dir = log_dir, update_freq='batch'
#     )
# 
#     es = tf.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', mode='max', verbose=1, patience=10)
#     mc = tf.keras.callbacks.ModelCheckpoint(fn_args.serving_model_dir, monitor='val_binary_accuracy', mode='max', verbose=1, save_best_only=True)
# 
# 
#     # Load the transform output
#     tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)
# 
#     # Create batches of data
#     train_set = input_fn(fn_args.train_files, tf_transform_output, 10)
#     val_set = input_fn(fn_args.eval_files, tf_transform_output, 10)
#     vectorize_layer.adapt(
#         [j[0].numpy()[0] for j in [
#             i[0][transformed_name(FEATURE_KEY)]
#                 for i in list(train_set)]])
# 
#     # Build the model
#     model = model_builder()
# 
# 
#     # Train the model
#     model.fit(x = train_set,
#             validation_data = val_set,
#             callbacks = [tensorboard_callback, es, mc],
#             steps_per_epoch = 1000,
#             validation_steps= 1000,
#             epochs=10)
#     signatures = {
#         'serving_default':
#         _get_serve_tf_examples_fn(model, tf_transform_output).get_concrete_function(
#                                     tf.TensorSpec(
#                                     shape=[None],
#                                     dtype=tf.string,
#                                     name='examples'))
#     }
#     model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)
# 
#

"""The next step is to define the Trainer() component. This component will receive several inputs as follows.

- module_file to receive a module file containing training functions along with several helper functions.
- examples to receive datasets from the ExampleGen component.
- schema to receive schema data from the SchemaGen component.
- transform_graph to receive the transform graph generated from the Transform component.
- train_args to accommodate training parameters.
- eval_args to accommodate testing or evaluation parameters.
"""

from tfx.proto import trainer_pb2

trainer  = Trainer(
    module_file=os.path.abspath(TRAINER_MODULE_FILE),
    examples = transform.outputs['transformed_examples'],
    transform_graph=transform.outputs['transform_graph'],
    schema=schema_gen.outputs['schema'],
    train_args=trainer_pb2.TrainArgs(splits=['train']),
    eval_args=trainer_pb2.EvalArgs(splits=['eval'])
)
interactive_context.run(trainer)

"""# Analysis and Validation

If the model development process runs smoothly, the next step is creating the analysis and validation stages.

## Resolver Component
To perform model analysis and validation, we need to provide a model baseline. This is especially important when we have more than one version of the model and want to compare two different versions of the model. To do this, we can utilize the Resolver() component.
"""

from tfx.dsl.components.common.resolver import Resolver
from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import LatestBlessedModelStrategy
from tfx.types import Channel
from tfx.types.standard_artifacts import Model, ModelBlessing

model_resolver = Resolver(
    strategy_class= LatestBlessedModelStrategy,
    model = Channel(type=Model),
    model_blessing = Channel(type=ModelBlessing)
).with_id('Latest_blessed_model_resolver')

interactive_context.run(model_resolver)

"""## Evaluator Component
After defining the Resolver component, the next step is to create some configurations to evaluate the model. These configurations are created using the TFMA library as follows.
"""

import tensorflow_model_analysis as tfma

eval_config = tfma.EvalConfig(
    model_specs=[tfma.ModelSpec(label_key='label')],
    slicing_specs=[tfma.SlicingSpec()],
    metrics_specs=[
        tfma.MetricsSpec(metrics=[

            tfma.MetricConfig(class_name='ExampleCount'),
            tfma.MetricConfig(class_name='AUC'),
            tfma.MetricConfig(class_name='FalsePositives'),
            tfma.MetricConfig(class_name='TruePositives'),
            tfma.MetricConfig(class_name='FalseNegatives'),
            tfma.MetricConfig(class_name='TrueNegatives'),
            tfma.MetricConfig(class_name='BinaryAccuracy',
                threshold=tfma.MetricThreshold(
                    value_threshold=tfma.GenericValueThreshold(
                        lower_bound={'value':0.5}),
                    change_threshold=tfma.GenericChangeThreshold(
                        direction=tfma.MetricDirection.HIGHER_IS_BETTER,
                        absolute={'value':0.0001})
                    )
            )
        ])
    ]

)

"""The EvalConfig is initialized with a model_specs parameter that identifies the model's label key as 'label', indicating the feature used as the ground truth for evaluation. The slicing_specs parameter is left empty, meaning evaluations will be conducted on the entire dataset without additional data slicing. The metrics_specs parameter defines a list of metrics to be calculated, including ExampleCount, AUC (Area Under the Curve), FalsePositives, TruePositives, FalseNegatives, TrueNegatives, and BinaryAccuracy. The BinaryAccuracy metric is further configured with a threshold that sets a lower bound of 0.5 for accuracy. Additionally, it specifies a change threshold to ensure that improvements in accuracy are considered significant if they exceed an absolute value of 0.0001, with the direction indicating that higher accuracy is better. This configuration is used to systematically evaluate and monitor the model's performance.

After creating the configuration that will be used to evaluate the model, the next step is to define the Evaluator component. This component will receive several inputs as follows.
- examples to receive the dataset from the ExampleGen component.
- model to receive the model generated from the Trainer component.
- baseline_model to accommodate the model baseline provided by the Resolver component.
- eval_config to receive the configuration to evaluate the model.
"""

from tfx.components import Evaluator
evaluator = Evaluator(
    examples=example_gen.outputs['examples'],
    model=trainer.outputs['model'],
    baseline_model=model_resolver.outputs['model'],
    eval_config=eval_config)

interactive_context.run(evaluator)

!pip show tensorflow-model-analysis

# Visualize the evaluation results
eval_result = evaluator.outputs['evaluation'].get()[0].uri
tfma_result = tfma.load_eval_result(eval_result)
tfma.view.render_slicing_metrics(tfma_result)

"""The insights from the TFMA visualization indicate that the model has a high AUC of 0.94411, suggesting strong discrimination between classes. The binary accuracy is 0.89266, reflecting good overall performance. However, there are some false negatives (72) and false positives (99), which could highlight areas for improvement in minimizing these errors.

# Model Deployment
In this project, I'll use TF-Serving to create the model serving at the machine learning pipeline that I created before.

To connect the machine learning pipeline with TF-serving, I need one of the TFXComponents called **Pusher**. This component will push the validated model to the target system deployment, both in the training and retraining stages.

To carry out its tasks, Pusher will check whether the model meets the following two criteria.

- Has the trained model passed the validation process by the Evaluator component?

- Does the trained model have a format that is suitable for the production environment? This will be validated by the InfraValidator component. This is an optional criterion, but highly recommended if you want to create a reliable machine learning system.

If these criteria are met, the Pusher component will save the model to the serving file path. This serving file path is what TF-Serving accesses to fetch the latest model and run it in the production environment.

## Adding Pusher Component
This component will receive input in the form of a trained model, evaluation results from the Evaluator component, and arguments related to the serving file path.
"""

from tfx.components import Pusher
from tfx.proto import pusher_pb2

pusher = Pusher(
model=trainer.outputs['model'],
model_blessing=evaluator.outputs['blessing'],
push_destination=pusher_pb2.PushDestination(
    filesystem=pusher_pb2.PushDestination.Filesystem(
        base_directory='serving_model_dir/tweet-sentiment-model'))

)

interactive_context.run(pusher)

"""# Downloading a Pipeline"""

import shutil
from google.colab import files

shutil.make_archive('/content/pipeline', 'zip', '/content/pipelines')

files.download('/content/pipeline.zip')

"""# Downloading the serving_model_dir"""

shutil.make_archive('/content/serving_model', 'zip', '/content/serving_model_dir')

files.download('/content/serving_model.zip')