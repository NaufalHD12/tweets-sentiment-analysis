{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_version_status': [{'state': 'AVAILABLE',\n",
      "                           'status': {'error_code': 'OK', 'error_message': ''},\n",
      "                           'version': '1735471095'}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pprint import PrettyPrinter\n",
    " \n",
    "pp = PrettyPrinter()\n",
    "pp.pprint(requests.get(\"http://localhost:8080/v1/models/tweet-sentiment-model\").json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing prediction service...\n",
      "\n",
      "Testing text 1: I love this product! It's amazing!\n",
      "\n",
      "Making request to: http://localhost:8080/v1/models/tweet-sentiment-model:predict\n",
      "Input text: I love this product! It's amazing!\n",
      "\n",
      "Model status:\n",
      "{'model_version_status': [{'state': 'AVAILABLE',\n",
      "                           'status': {'error_code': 'OK', 'error_message': ''},\n",
      "                           'version': '1735471095'}]}\n",
      "\n",
      "Raw response:\n",
      "{\n",
      "    \"predictions\": [[0.0193230305]\n",
      "    ]\n",
      "}\n",
      "\n",
      "Parsed response:\n",
      "{'predictions': [[0.0193230305]]}\n",
      "Prediction score: 0.019\n",
      "Sentiment: positive\n",
      "\n",
      "Testing text 2: This is terrible, I hate it.\n",
      "\n",
      "Making request to: http://localhost:8080/v1/models/tweet-sentiment-model:predict\n",
      "Input text: This is terrible, I hate it.\n",
      "\n",
      "Model status:\n",
      "{'model_version_status': [{'state': 'AVAILABLE',\n",
      "                           'status': {'error_code': 'OK', 'error_message': ''},\n",
      "                           'version': '1735471095'}]}\n",
      "\n",
      "Raw response:\n",
      "{\n",
      "    \"predictions\": [[0.748471618]\n",
      "    ]\n",
      "}\n",
      "\n",
      "Parsed response:\n",
      "{'predictions': [[0.748471618]]}\n",
      "Prediction score: 0.748\n",
      "Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "from pprint import PrettyPrinter\n",
    "import base64\n",
    "\n",
    "def create_tf_example(text, id_num=1):\n",
    "    \"\"\"\n",
    "    Create a TensorFlow Example message with all required features.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The tweet text to classify\n",
    "        id_num (int): An ID number for the example\n",
    "    \"\"\"\n",
    "    feature = {\n",
    "        'tweet': tf.train.Feature(\n",
    "            bytes_list=tf.train.BytesList(value=[text.encode('utf-8')])\n",
    "        ),\n",
    "        'id': tf.train.Feature(\n",
    "            int64_list=tf.train.Int64List(value=[id_num])\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(feature=feature)\n",
    "    )\n",
    "    \n",
    "    return example.SerializeToString()\n",
    "\n",
    "def make_prediction(text, server_url='http://localhost:8080'):\n",
    "    \"\"\"\n",
    "    Make predictions using deployed TensorFlow Serving model\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to classify\n",
    "        server_url (str): URL where TensorFlow Serving is running\n",
    "    \n",
    "    Returns:\n",
    "        float: Prediction probability (0-1)\n",
    "    \"\"\"\n",
    "    # Construct the REST API endpoint\n",
    "    model_name = 'tweet-sentiment-model'\n",
    "    predict_url = f\"{server_url}/v1/models/{model_name}:predict\"\n",
    "    \n",
    "    # Create TF Example\n",
    "    tf_example = create_tf_example(text)\n",
    "    \n",
    "    # Create the request body\n",
    "    input_data = {\n",
    "    \"instances\": [\n",
    "        {\"b64\": base64.b64encode(tf_example).decode('utf-8')}\n",
    "    ]\n",
    "}\n",
    "\n",
    "    \n",
    "    # Debug information\n",
    "    print(f\"\\nMaking request to: {predict_url}\")\n",
    "    print(f\"Input text: {text}\")\n",
    "    \n",
    "    try:\n",
    "        # First verify the model is available\n",
    "        model_status_url = f\"{server_url}/v1/models/{model_name}\"\n",
    "        status_response = requests.get(model_status_url)\n",
    "        status_response.raise_for_status()\n",
    "        print(\"\\nModel status:\")\n",
    "        pp = PrettyPrinter()\n",
    "        pp.pprint(status_response.json())\n",
    "        \n",
    "        # Make prediction request\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        response = requests.post(predict_url, json=input_data, headers=headers)\n",
    "        \n",
    "        # Print raw response for debugging\n",
    "        print(\"\\nRaw response:\")\n",
    "        print(response.text)\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse the response\n",
    "        result = response.json()\n",
    "        print(\"\\nParsed response:\")\n",
    "        pp.pprint(result)\n",
    "        \n",
    "        prediction = result['predictions'][0][0]  # Get first prediction\n",
    "        return float(prediction)\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"\\nError details:\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        if hasattr(e, 'response') and e.response is not None:\n",
    "            print(f\"Response status code: {e.response.status_code}\")\n",
    "            print(f\"Response text: {e.response.text}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Test texts\n",
    "    texts = [\n",
    "        \"I love this product! It's amazing!\",\n",
    "        \"This is terrible, I hate it.\",\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTesting prediction service...\")\n",
    "    for i, text in enumerate(texts, 1):\n",
    "        print(f\"\\nTesting text {i}: {text}\")\n",
    "        prediction = make_prediction(text)\n",
    "        \n",
    "        if prediction is not None:\n",
    "            sentiment = \"negative\" if prediction >= 0.5 else \"positive\"\n",
    "            print(f\"Prediction score: {prediction:.3f}\")\n",
    "            print(f\"Sentiment: {sentiment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-tfx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
